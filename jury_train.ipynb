{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9rkhPO-urbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9f1ff8-7334-4a89-ec96-ff6033c14d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFkhze37lSMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15322710-9252-41fc-8444-3552e5617a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32X2beYkj_tE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow_recommenders\n",
        "!pip install nltk emoji==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeaRJDYKkRub"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import math\n",
        "from glob import glob\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Embedding, LSTM, MaxPooling1D, Conv1D\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow_recommenders as tfrs\n",
        "import gensim\n",
        "from nltk.tokenize import wordpunct_tokenize, word_tokenize\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "JYyJxP2lBmtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qbtfXHruJEc"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_name='vinai/bertweet-base', max_length=128, \n",
        "                hidden_size=768, n_annotators=35804, n_groups=331,\n",
        "                classifier_dropout=0.2):\n",
        "    bert = TFAutoModel.from_pretrained(model_name)\n",
        "    input_ids = Input(shape=(max_length,), name='input_ids', dtype=\"int32\")\n",
        "    attention_mask = Input(shape=(max_length,), name='attention_mask', dtype=\"int32\")\n",
        "    bert.layers[0]._name = 'roberta'\n",
        "    x1 = bert.roberta(input_ids, attention_mask=attention_mask)[1]\n",
        "    x = [x1]\n",
        "    annotator_id = Input(name='annotator_id', shape=(1, ))\n",
        "    x2 = Embedding(n_annotators, 32, name='annotator_embed')(annotator_id)\n",
        "    x2 = tf.keras.layers.Reshape((32, ))(x2)\n",
        "    x.append(x2)\n",
        "    group_id = Input(name='group_id', shape=(1, ))\n",
        "    x3 = Embedding(n_groups, 32, name='group_embed')(group_id)\n",
        "    x3 = tf.keras.layers.Reshape((32, ))(x3)\n",
        "    x.append(x3)\n",
        "    x = tf.concat(x, axis=1)\n",
        "    for i in range(3):\n",
        "        x = tfrs.layers.dcn.Cross(projection_dim=hidden_size, \n",
        "                                  kernel_initializer=\"glorot_uniform\", \n",
        "                                  name=f'cross_{i}')(x)\n",
        "        x = Dropout(classifier_dropout)(x)\n",
        "    for i in range(3):\n",
        "        x = tf.keras.layers.Dense(hidden_size, activation=\"relu\", name=f'dense_{i}')(x)\n",
        "        x = Dropout(classifier_dropout)(x)\n",
        "    out = Dense(1, name=\"out\")(x)\n",
        "    model = Model(inputs={'input_ids': input_ids, 'attention_mask': attention_mask, \n",
        "                          'annotator_id': annotator_id, 'group_id': group_id}, outputs=out)\n",
        "    return model"
      ],
      "metadata": {
        "id": "itZ0CV748JC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = pd.read_parquet('toxicity_ratings.parquet')\n",
        "input_ids = np.load('input_ids_toxicity.npy')\n",
        "attention_mask = np.load('attention_mask_toxicity.npy')\n",
        "\n",
        "model = build_model()"
      ],
      "metadata": {
        "id": "K2FnmRCOCC8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('roberta').trainable = True"
      ],
      "metadata": {
        "id": "kZHobOpvCsY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(df_merged, test_size=1/10, random_state=42)\n",
        "inputs = {'input_ids': input_ids[train['comment_index'], :], 'attention_mask': attention_mask[train['comment_index'], :]}\n",
        "inputs['annotator_id'] = np.array(train['annotator_id'])\n",
        "inputs['group_id'] = np.array(train['group_id'])\n",
        "inputs_val = {'input_ids': input_ids[val['comment_index'], :], 'attention_mask': attention_mask[val['comment_index'], :]}\n",
        "inputs_val['annotator_id'] = np.array(val['annotator_id'])\n",
        "inputs_val['group_id'] = np.array(val['group_id'])"
      ],
      "metadata": {
        "id": "zsXNn2AsCsbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n",
        "              loss=tf.keras.losses.MeanAbsoluteError(), \n",
        "              metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "checkpoint = ModelCheckpoint('jury-{epoch:03d}', verbose=1, monitor='val_loss', \n",
        "                             save_best_only=True, mode='auto')  \n",
        "model.fit(inputs, np.array(train.labels), \n",
        "          validation_data=(inputs_val, np.array(val.labels)), \n",
        "          batch_size=512, epochs=2, callbacks=[checkpoint])\n",
        "model.get_layer('roberta').trainable = False\n",
        "model.fit(inputs, np.array(train.labels), \n",
        "          validation_data=(inputs_val, np.array(val.labels)), \n",
        "          batch_size=512, epochs=6, callbacks=[checkpoint])\n",
        "model.save_weights('jury')"
      ],
      "metadata": {
        "id": "kecGUGaHDGlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1ZDaMUV9nPoyq-8uXJ9kA2k0An3k5HR0B",
      "authorship_tag": "ABX9TyPgYmC+3yWQkVNM7aICNScF"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}